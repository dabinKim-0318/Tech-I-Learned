
# 프로세스<a name = "outline"></a>
<details>
   <summary><span style="border-bottom:0.05em solid"><strong>프로세스와 스레드 </strong></span></summary>
<br />
 

### 📌프로세스  
- **프로세스는 컴퓨터 시스템의 작업 단위**로 태스크라고도 부름
  - 저장장치에 저장되어 있는 정적인 상태인 **프로그램이 운영체제로부터 프로세스 제어블록을 받아 메모리상에 올라오면 "프로세스"** 
  - 프로세스 제어 블록이 없으면 프로그램이 프로세스로 전환되지 못하며, 어떤 프로그램이 프로세스가 되었다는 것은 운영체제로부터 프로세스 제어 블록을 받았다는 의미
  - 프로그램 실행->프로세스
  - 자신만의 고유 공간과 자원을 할당받아 사용(코드/데이터/힙/스택)
  
### 📌멀티프로세스  
- 하나의 응용프로그램을 여러 개의 프로세스로 구성하여 각 프로세스가 하나의 작업을 처리하도록 하는 것.
- 서로 다른 둘 이상의 프로그램을 실행하기 위해 각각의 프로세스를 생성하는 것

- 장점
  - 프로세스 중 하나에 문제가 생겨도 다른 프로세스에 영향을 주지 않아, 작업속도가 느려지는 손해정도는 생기지만 정지되거나 하는 문제는 발생하지 않는다.

- 단점
  - **각각 독립된 메모리 영역**을 가지고 있어, **작업량이 많을수록 Context Switching이 자주** 일어나서 **주소 공간의 공유가 잦을 경우 캐시 메모리 초기화 등 무거운 작업**이 자주 진행되면 **오버헤드**가 발생한다.
  

### 📌Context Switching
- Context Switching 이란 CPU가 이전의 프로세스 상태를 PCB에 보관하고, 또 다른 프로세스의 정보를 PCB로 읽어 레지스터에 저장하는 과정
- Context Switching은 주로 인터럽트가 발생하거나, 실행 중인 CPU 사용 허가 시간(Time Quantum)을 모두 소모하거나, I/O 입출력을 위해 대기해야 하는 경우 Context Switching이 발생한다

  - 만약 컴퓨터가 매번 하나의 Task만 처리할 수 있다면? 다음 Task를 처리하기 위해서 현재 Task가 끝날 때까지 기다려야한다
  - 다양한 사람들이 동시에 사용하는 것처럼 하기 위해서 Context Switching이 필요( CPU는 한번에 하나의 프로세스만 실행 가능)
     - 컴퓨터 멀티태스킹을 통해 빠른 반응속도로 응답 가능합니다.
     - 빠르게 Task를 바꾸면서 실행하기에 사람은 실시간처리가 되는 것처럼 보입니다.
     - CPU가 Task를 바꿔가며 실행하기 위해 Context Switching이 필요하게 되었습니다.
  
### 📌Context Switching 오버헤드

- 프로세스들의 시간 할당량은 시스템 성능의 중요한 역할을 한다. 시간 할당량이 적을수록 사용자 입장에서는 여러 개의 프로세스가 거의 동시에 수행되는 느낌을 갖지만 Context Switching의 수가 늘어난다. 프로세스의 실행을 위한 부가적인 활동을 **오버헤드**(간접 부담 비용)이라고 하는데, 이 또한 Context Switching 수와 같이 늘어나게 된다. 
- 시간 할당량이 적어지면 : Context Switching 수, 오버헤드가 증가하지만 여러 개의 프로세스가 동시에 수행되는 느낌을 갖는다.
- 시간 할당량이 커지면 : Context Switching 수, 오버헤드가 감소하지만 여러 개의 프로세스가 동시에 수행되는 느낌을 갖지 못한다.

- **프로세스를 수행하다가 I/O event가 발생하여 BLOCK 상태로 전환시켰을 때, CPU가 그냥 놀게 놔두는 것보다 다른 프로세스를 수행시키는 것이 효율적**이므로, CPU에 계속 프로세스를 수행시키도록 하기 위해서 다른 프로세스를 실행시키고 Context Switching을 할 때 Overhead가 발생한다다.

- 전체적으로 봤을 때 이익이 되니까 overhead를 감수하더라도 Context Switching을 하는 거고 그래서 운영체제가 CPU를 관리하는 것. 사용자가 너무 기다리지 않게 관리하기 위해서 반드시 해줘야 하는게 Context Switching이고 이것이 대표적으로 운영체제가 하는 CPU관리 한다.
 
***
   
### 📌스레드
- 둘 이상의 실행 흐름이 필요해 프로세스를 생성하는 작업은 부담스러움
    - why? 많은 수의 프로세스 생성은 빈번한 컨텍스트 스위칭으로 이어져 성능에 영향을 미치기 때문
    - 해결방법은? 저장하고 복원하는 컨텍스트 정보의 개수를 줄이면 된다. 즉 컨텍스트 정보란 프로세스 상테 정보와 관련이 있으므로 →프로세스 상태 정보를 줄여야 한다는 것이다.
- 컨텍스트 스위칭이 필요한 이유는?
    - 프로세스들이 독립되어 있기 때문
    - if) 두 프로세스가 완전히 별개가 아닌 반을 공유하는 구조라면?
    - 컨텍스트 스위칭 발생 시 저장 및 복원 정보도 반으로 줄게됨
    - →스레드가 등장
- 해결책:스레드
    - 별개의 프로그램이라면 독립된 프로세스 구조가 필요함
    - 하지만, 하나의 프로그램 내 둘 이상의 실행흐름을 만들경우, 모든것을 독립할 필요가 x
   
- **CPU 스케줄러가 CPU에 작업을 요청하는 실행단위=프로세스 안에서 실행되는 흐름단위**
  - 운영체제가 프로세스 제어블록을 생성하고 작업에 필요한 메모리 영역을 확보한 후 준비된 프로세스를 준비큐에 삽입  
  ->프로세스가 생성되면 CPU스케줄러는 프로세스가 해야하는 일을 CPU에 전달하고 실제 작업은 CPU가 수행  
  ->이때 CPU스케줄러가 CPU에 전달하는 일 하나는 "스레드"  
  - 스레드는 스택영역만 따로 할당받고 나머지 영역은 스레드끼리 서로 공유

     
 
### 📌멀티스레드
- 예전엔 여러 작업을 동시에 처리하기 위해 fork() 시스템 호출로 프로세스를 전환하는 방법을 이용했음 = 멀티태스크 ex) 워드랑 프린트 스풀러는 독립적으로 작동하다가 필요할 때 출력할 데이터를 프로세스간 통신을 이용해 주고받음     
  ->프로세스의 정적영역(코드/데이터) 영역 메모리 중복 
  ->비슷한 일을 하는 여러 프로세스를 만들지 말자   
  ->정적영역 공유면서 여러개의 일을 하나의 프로세스 내에서 하자   
  ->CPU가 여러 스레드 조금씩 돌면서 병렬적으로 작업  
  ->코드 영역등을 함께 공유해서 자원 낭비 막고 효율성 향상!!! 

- 멀티스레드 장점
    - **자원공유**: 프로세스가 가진 자원을 모든 스레드가 공유->작업 원활   
    - **응답성 향상**: 다른 스레드가 작업을 계속하여 사용자의 작업 요구에 빨리 응답 가능   
   ex) 채팅+파일 주고받기 / 워드 작성+틀린글자 찾아줌 / 비디오 플레이어 입출력(재생파일 저장장치로부터 가져옴)+영상재생   
  
 - 멀티스레드 단점
    - **독립X**: 모든 스레드가 자원공유하니까 한 스레드에 문제 발생하면 전체 프로세스에 영향  
  EX)익스플로러:프로세스1+멀티스레드 / 크롬:멀티태스크 -> 다른 화면 종료되어도 전체종료X
    - **동기화**:자원 공유로 인한 일치 문제 등
    - **오버헤드**: 싱글 코어 멀티 스레딩은 스레드 생성 시간이 오히려 오버헤드로 작용해 단일 스레드보다 느리다.
 
 - 안전성 Critical Section 대비함
   - 하나의 스레드가 공유 데이터 값을 변경하는 시점에 다른 스레드가 그 값을 읽으려할 때 발생하는 문제를 해결하기 위한 동기화 과정
### 📌싱글스레드
- 하나의 프로세스에서 오직 하나의 스레드로만 실행
- 장점
  - **문맥 교환X**: 문맥 교환은 여러 개의 프로세스가 하나의 프로세서를 공유할 때 발생하는 작업으로 많은 비용을 필요로 한다.

  - **동기화X**: 여러 개의 스레드가 프로세스의 자원을 공유할 경우, 각 스레드가 원하는 결과를 얻게 하려면 공용 자원에 대한 접근을 제어해야 한다. 쉽게 말해서, 모든 스레드가 일정 자원에 동시에 접근하거나, 똑같은 작업을 실행하려는 경우, 에러가 발생하거나 원하는 값이 나오지 않는다. 그래서, 스레드들이 동시에 같은 자원에 접근하지 못하도록 제어해줘야만 한다. 이 작업은 프로그래머에게 많은 노력을 요구하고 비용을 발생시킨다.

- 단점
  - **연산량이 많은 작업을 하는 경우, 그 작업이 완료되어야 다른 작업을 수행**할 수 있다
  EX)서버 통신 완료 되어야 UI클릭 가능

  - **에러 처리를 못하는 경우 멈춘다.**
멀티 스레드 모델은 에러 발생 시 새로운 스레드를 생성하여 극복한다. 다만, 새로운 스레드 생성이나 놀고 있는 스레드 처리에 비용이 발생한다.
   
***
   
### 📌멀티스레드 vs 싱글스레드

- **단순히 CPU만을 사용하는 계산작업이라면, 오히려 멀티스레드보다 싱글스레드로 프로그래밍하는 것이 더 효율적**이다.
=> a) 두 개의 작업을 하나의 스레드로 처리하는 경우 VS b) 두 개의 스레드로 처리하는 경우
b의 경우는 짧은 시간 동안 2개의 스레드가 번갈아가면서 작업을 수행한다. 그래서 동시에 두 작업이 처리되는 것과 같이 느끼게 된다.
하지만, 오히여 두 개의 스레드로 작업한 시간이 싱글스레드로 작업한 시간보다 더 걸릴 수도 있는데, 그 이유는 **스레드 간의 작업전환(context switching)에 시간이 걸리기 때문**이다.
다시 말해서, 단순히 CPU만을 사용하는 작업은 싱글 스레드가 멀티 스레드보다 빠르다.
 
### 📌스레드 vs 프로세스
-  프로세스는 운영체제의 **작업단위**, 스레드는 CPU 스케줄러가 CPU에 작업을 요청하는 **실행단위** 
-  프로세스는 **자신만의 고유 공간과 자원 할당** 받음 / 스레드는 **다른 스레드와 자원 공유**
- 프로세스는 완전히 독립된 두 개의 프로그램 실행을 위해 사용됨
- 스레드는 하나의 프로그램 내 둘 이상의 프로그램 흐륾을 만들어 내기 위해 만들어진 것
- 스레드는 프로세스와 다르게 공유하는 상태정보들이 있음 →이것이 스레드의 컨텍스트 스위칭을 빠르게 하는 요인    
***   
 
### 👉예상질문) 스레드의 등장배경은?
둘 이상의 실행흐름이 필요해 프로세스를 생성하는 작업은 빈번한 컨텍스트 스위칭으로 이어져 성능에 영향을 미치게 됩니다.
이러한것을 해결할 수 있는 방법은 저장 및 복원해야하는 컨텍스트의 정보의 수를 줄이면 됩니다.만약 두 프로세스가 완전
히 별개가 아닌 일정량을 공유하는 구조가 될 경우 성능 저하의 문제점을 보완할 수 있어 스레드가 등장하게 되었습니다.
   
### 👉예상질문) 멀티 프로세스로 처리 가능한 걸 굳이 멀티 스레드로 하는 이유는?
프로세스를 생성하여 자원을 할당하는 시스템 콜이 감소함으로써 자원의 효율적 관리가 가능 프로세스 간의 통신(IPC)보다 스레드 간의 통신 비용이 적어 작업들 간 부담이 감소 대신, 멀티 스레드를 사용할 때는 공유 자원으로 인한 문제 해결을 위해 '동기화'에 신경써야 한다.   
   
### 👉예상질문) 멀티 프로세스를 사용해야 하는 경우와 멀티 스레드를 사용해야 하는 경우를 설명해보세요
멀티 프로세스를 사용해야 하는 경우는  서로 다른 둘 이상의 프로그램을 실행할때 입니다. 멀티 스레드를 사용해야 하는 경우는 하나의 프로그램이 두 가지 이상의 일을 동시에 처리해야 할 때 입니다.   
   
### 👉예상질문) 이런 상태일때는 무슨 스레드 쓸까?
   
***
   
  </details>

<details>
 <summary><span style="border-bottom:0.05em solid"><strong>사용자 수준 스레드, 커널 수준 스레드 </strong></span></summary>
<br />

### 📌스레드 종류
스레드는 운영체제에 따라  
1.사용자 수준 스레드 2.커널 수준 스레드 3.혼합형 스레드
   
### 📌사용자 수준 스레드
- 스레드와 관련된 모든 행위를 스레드 관련 라이브러리를 이용해서 사용자 영역에서 하는 스레드
- 스레드 관련 라이브러리는 스레드 생성, 종료, 스레드 간 메시지 전달, 스레드 스케줄링, 컨텍스트 등 정보 보관
- 스레드 관련 모든 행위를 "사용자 영역"에서 하기 때문에 커널은 스레드의 존재를 모르고 개입도 안함
   
- 장점
   - 높은 이식성: 커널에 독립적으로 스케줄링 할 수 있어, 모든 운영체제에 적용 가능
   - 스케줄링을 위해 커널을 호출하지 않으며로 커널영역으로 전환하는 오버헤드가 줄어듬
   
- 단점
   - 커널이 다른 스레드의 존재를 알지 못하므로 하나의 스레드가 블락되면 다른 프로세스에게 CPU를 뺏김
   - 스레드들을 보호 못해줌: 커널에서 이루어지는 스레드 간 보호 방법을 사용 못한다. 스레드 라이브러리에서 제공해주면 가능
   
   
### 📌커널 수준 스레드
- 커널이 스레드와 관련된 모든 작업을 관리하는 형태의 스레드
   
- 장점
   - 하나의 프로세스에 여러 스레드들이 동시에 실행 가능. 하나의 스레드가 대기 상태가 되어도 다른 스레드 실행 가능
- 단점
   - 커널이 모든 프로세스와 스레드에 대한 정보를 유지하고 있어야 하니까 오버헤드가 커짐
   
 ### 📌혼합형 스레드
- 커널 수준 스레드의 단점(스레드의 수가 제한된다)과 유저 수준 스레드의 단점(시스템 콜이 일어날 때마다 다른 스레드가 멈춘다)를 보완하기 위해 제시된 방법
- 사용자 수준 스레드와 커널 스레드 사이에 경량 프로세스 스레드를 둔 형태   
- 사용자 수준 스레드 하나가 시스템 콜의 호출에 의해 중지되더라도, 다른 경량 프로세스 스레드에서 동작하던 스레드는 계속 동작함
- 효율성과 유연성을 모두 잡을 수 있게 됨   
   
 </details>


<details>
 <summary><span style="border-bottom:0.05em solid"><strong>스케줄러</strong></span></summary>
<br />
   
 ### 📌스케줄러
 - 프로세스가 생성되고 종료될때까지 **모든 상태 변화를 조정**하는 일을 함  
   왜? CPU를 잘 쓰려고. 프로세스를 잘 배정해서!
   
### 📌스케줄링 구분
- CPU스케줄러도 관리의 범주를 나누어 스케줄링 하는데, "규모"에 따라 장기, 중기, 단기 스케줄링으로 구분

### 📌장기 스케줄러
- 프로세스에게 메모리같은 각종 자원을 줄까? 말까?를 관리하기 때문에 메모리에 올라갈 프로세스 수도 제어해야한다.
- 메모리에 올라갈 프로그램 수를 결정하니까 실행 가능한 프로세스의 수를 조절하는 역할
- 하지만 오늘날 우리가 사용하는 시스템에는 장기 스케줄러가 없다! 프로그램이 시작되면 곧바로 메모리에 올라간다= 프로그램 100개 실행하면 전부 메모리에 올라각서 CPU얻기를 기다리는 준비 상태가 된다.
- 그럼 우리가 사용하는 프로그래밍의 멀티 프로그래밍을 제어하는건 누구? =? 중기 스케줄러
- 어떤 프로세스가 메모리에 올라가고 싶은데 메모리 줄까 말까를 "중기 스케줄러"가 결정
### 📌중기 스케줄러   
메모리 공간이 부족해서 시스템 과부하가 걸리면 프로세스 통째로 메모리에서 디스크로 쫒아내고 "보류(일시정지)" 상태로 보냄
 
### 📌단기 스케줄러  
 - 준비상태의 프로세스 중 어떤걸 실행상태로 옮길까? 등을 결정
 - 프로세스에 CPU를 주는 문제를 담당->잦은 스케줄링 필요해서 매우 빨라야함
 
### 📌CPU 스케줄링이 필요한 경우
- I/O요청하는 시스템 콜: 실행->대기 
- 타임아웃/인터럽트: 실행->준비  
- I/O완료 후 인터럽트: 대기->준비

### 📌스케줄링 척도
- CPU Utilization(이용률) : 전체 시간 중 CPU가 놀지 않고 일한 시간, 이용률이 높을수록 좋음</li>
- Throughput(처리량) : 단위 시간당 처리량, CPU가 얼마나 많은 일을 했는가, 높을수록 좋음</li>
- Turnaround Time(소요시간, 반환시간) : CPU 사용한 시간 + 기다린 시간, 짧을수록 좋음</li>
- Waiting Time(대기시간) : 프로세스가 Ready Queue에서 기다린 전체 시간의 합, 짧을수록 좋음</li>
- Response Time(응답시간) : 프로세스가 Ready Queue에 들어가서 최초로 CPU 얻기까지의 시간, 짧을수록 좋음</li>

### 📌CPU 스케줄링 알고리즘
- 스케줄링 알고리즘은 비선점, 선점형 알고리즘으로 나뉜다 
- 선점형: CPU할당 받아 실행중이어도 운영체제가 CPU 강제로 뺏기 가능 =>라운드로빈, SRT , 다단계 ~
- 비선점형: 작업이 끝날때까지 CPU안놔줌 => FCFS, SJF, HRN
- 둘다가능: 우선순위 스케줄링
  
 ***  
   
 </details>

<details>
 <summary><span style="border-bottom:0.05em solid"><strong>인터럽트</strong></span></summary>
<br />

- 입출력장치랑 상호작용하는 3가지 방법
#### 1. 폴링방식: 초기의 컨퓨터 시스템에는 주변 장치가 많지 않았어서 CPU가 주변 입출력 장치들(키보드, 센서, LCD 등)에서의 변화를 지속적으로 계속 확인하고 그에 따라 프로그램을 처리하는 방식을 말한다.
   - EX) 프로그램은 쉽게 구현할 수 있지만 예를 들어 컴퓨터의 키보드를 폴링방식으로 구현한다고 생각해보자. 컴퓨터로 영화를 보고 있는데도 키보드를 치고 있는지 아닌지 계속 확인하는 작업을 한다면 CPU의 성능을 제대로 활용할 수 없다. 하지만 아두이노, AVR 등에서 간단한 프로젝트를 구현할 때는 코드를 작성하기 간편하다는 장점 때문에 폴링 방식을 사용하기도 한다. 폴링 방식이 꼭 나쁜 건 아니다. 드론을 만들 때 자세 센서에서 계속 값을 읽어와야하는데, 폴링 방식으로 자세 센서와 상호작용했다.
   - 장점: 구현이 간단
   - 단점: CPU가 입출력장치까지 관여해야하므로 작업 효율 떨어짐 / 한 루프를 다 돌아야지만 상태 변화를 확인할 수 있음
   
#### 2. 인터럽트
   - 입출력 관리자가 CPU에게 보내는 완료신호
   - 예외현상이 발생해 CPU의 정상적인 동작을 방해한 상태
   - 인터럽트 방식은 하드웨어 지원을 받아야하는 제약이 있지만 폴링에 비해 신속대응이 가능
   - 실시간 대응이 필요할 때 필수적 기능
   - 발생시기를 예측하기 힘든 경우에 컨트롤러가 가장 빠르게 대응할 수 있는 방법
   
#### 3. DMA(Direct Memory Access)
   - 폴링은 프로그램에 의한 입출력 방식이여서 CPU가 계속 주변장치를 감시하기 때문에 CPU의 효율이 떨어진다고 했다. 이런 점을 개선하기 위해 CPU개입없이 주변장치와 상호작용하는 DMA(Direct Memory Access)가 개발되었다.
   - 그럼 CPU개입이 적은 인터럽트를 사용하면 되지 않을까?
   - 인터럽트를 사용하더라도 여전히 CPU는 데이터 전송을 하기위해 개입하게 되고, 입출력하는 시간이 길어지게 되면 CPU는 입출력하는 동안 다른 일을 못하게 된다.
   - 그럼 CPU는 무엇을 하면 될까? CPU는 DMAC(DMA controller)에게 입출력 관련 정보만 주고 다른일을 계속 하면된다.
   - 입출력 정보에는 뭐가 있을까? CPU는 DMAC에게 어떤 source를 보내는지, 목적지는 어딘지, 얼마만큼 보내는지를 알려주고 언제 전송을 시작하고 어떤 방식으로 할지만 알려주면 DMAC가 알아서 데이터를 전송해준다. 
   - 전송이 끝나면 DMAC는 CPU에게 인터럽트를 발생시킨다. 결론적으로 CPU는 전송의 시작과 끝에만 관여하게 되고 직접적이 데이터 전송은 DMAC가 하게 되는 것이다.
   
### 📌인터럽트 처리 과정
cpu 실행하고 있는 도중에 입출력 장치에서 필요할 때 마다 즉각적으로 CPU에게 인터럽트 신호를 전송하게 된다. 해당 인터럽트가 요청한 작업을 실행하기 위해 하고있는 동작을 멈추고 ISR(인터럽트 처리 루틴)으로 이동한다. ISR이 완료되면 CPU는 수행을 멈춘 곳으로 되돌아가 중지된 작업을 계속한다. 
   
   ![다운로드](https://user-images.githubusercontent.com/84564695/187033468-7d955e94-a877-43e9-99ed-852b6df6c14a.png)

   
- 평소에는 노란색 LED와 파란색 LED를 번갈아가며 1초마다 깜빡이다가 스위치를 누르면 1초간 빨간색 LED를 켜고 다시 노란색, 파란색 LED를 계속 깜빡이게 개발한다고 생각해보자. 이 상황에서 노란색 LED와 파란색 LED가 깜빡이는 것은 순차적이고 반복적인 작업이지만 스위치가 눌러지는 예외 상황이 발생하면 빨간색 LED를 즉시 켜야 한다. 

- 이처럼 **반복적이고 순차적인 작업이 아닌 예외 적으로 즉시 처리되기를 원하는 명령이나 동작을 인터럽트 또는 예외 처리**라고 부른다.

 
인터럽트가 발생하게 되면 일단,


1. 실행중인 작업을 중단하고 현재 태스크의 Context(레지스터 값)을 스택에 저장한다. 
현재 프로그램 상태(PC, SR)를 저장하는 이유는 인터럽트 처리를 끝내고 작업을 원상 복구하기 위해서다. 
예를 들어, 노란색 LED를 켜고 나서 인터럽트가 발생하여 빨간색 LED를 켰다. 인터럽트가 발생했을 때, 그다음 켜야 할 색이 파란색이란 것을 저장했었어야 빨간색 LED 다음에(인터럽트를 처리하고) 파란색 LED를 켜야 한다는 것을 알 수 있을 것이다. 
이렇게 인터럽트 요청에 의해 기존의 프로세스의 상태를 저장하고 CPU가 우선순위의 프로세스를 수행하도록 새로운 프로세서의 상태, 레지스터값을 교체하는 것을 Context Switching이라고 한다. 

 2. 인터럽트를 처리하기 위해서 인터럽트 벡터 테이블을 참조하여 ISR 주소 값을 얻는다. 
인터럽트 벡터 테이블이란 인터럽트 핸들러(ISR) 주소를 저장하고 있는 테이블을 말하고, 인터럽트 핸들러(Interrupt Service Routine)는 인터럽트를 처리하기 위한 코드이고, 함수의 형태를 가지고 있다. 

3. 인터럽트 핸들러를 실행한다. 

4. 원래 작업으로 돌아오기위해 아까 스택에 저장해두었던 Context를 복원한다. 

5. PC값을 이용해 인터럽트 발생 전 수행하던 작업을 계속 진행한다 .


### 📌인터럽트 종류
 #### 외부 인터럽트 VS 내부 인터럽트 
 - 외부 인터럽트: 입출력 장치, 타이밍 장치. 전원등 외부적인 요인으로 발생
    
    ex)전원 이상, 입출력 인터럽트(키보드, 프린터기 등), 타이머 인터럽트
    
- 내부 인터럽트: Trap이라고 불림, 잘못된 명령이나 데이터를 사용할 때 발생
    
    ex)0으로 나누기 발생, 오버플로우, 명령어를 잘못 사용한 경우(Exception)
    
 #### 소프트웨어 인터럽트
- 소프트웨어가 발생시키는 인터럽트. 소프트웨어(사용자 프로그램)가 스스로 인터럽트 라인을 세팅함
- 프로그램 처리 중 명령의 요청에 의해 발생
- 대표적인 형태는 프로그램에서 감시 프로그램 호출(SVC) 호출
- SVC(SuperVisor Call)
    - 명령어 수행시 문제가 생겼을 때, **프로세서에게 컴퓨터의 제어권을 OS의 감시자(supervisor)에게 넘기라는 명령**
    - 사용자가 프로그램을 실행시키거나 감시프로그램(Supervisor)을 호출하는 동작을 수행하는 경우
    - 복잡한 입출력 처리를 하는 경우
    - system call
 </details>


<details>
 <summary><span style="border-bottom:0.05em solid"><strong>프로세스 동기화</strong></span></summary>
<br />

 ### 📌프로세스 동기화
   - 하나의 자원을 한 순간에 하나의 프로세스만이 이용하도록 제어!!하는 것
   
 ### 📌원인
   - 프로세스가 1개가 아니라 발생하는 문제
   - 프로세스들이 공통된 자원에 서로 접근하려해서 -> 여러 스레드,프로세스가 접근하려 하는 상태가 경쟁상태
   
 ### 📌문제
   - `데이터 불일치`: 여러개의 스레드들이 공유하는 데이터를 변경할 수 있는 코드영역=임계구역 문제
   - `프로세스 실행 순서 제어`: 프로세스 여러개라 원하는대로 실행 순서 제어
   
  ### 📌해결방안->화장실은 한명만 밖에 있는 사람 하루종일 기다리지 말고 화장실 갈 사람 정하는것도 일정시간 안에
   - `상호배타`: 오직 한 쓰레드만이 진입 가능하다. 한 쓰레드가 임계구역에서 수행 중인 상태에서는 다른 쓰레드는 절대 이 구역에 접근할 수 없다.
  - `진행`: 한 임계구역에 접근하는 쓰레드를 결정하는 것은 유한 시간 이내에 이루어져야한다.
  - `유한대기`: 임계구역으로 진입하기 위해 대기하는 모든 쓰레드는 유한 시간 이내에 해당 임계구역으로 진입할 수 있어야 한다. 
  
***
   
 </details>

<details>
 <summary><span style="border-bottom:0.05em solid"><strong>시스템 콜</strong></span></summary>
<br />

 ### 📌시스템콜 왜 필요해?
- 응용프로그램이 하드웨어에 접근하거나 **운영체제가 제공하는 서비스를 이용**하고자 할때 시스템 호출사용해야함
- 커널(운영체제 핵심기능 모아둠)이 제공하는 시스템 자원과 연관된 함수, 인터페이스
  - 우리가 일반적으로 쓰는 프로그램은 응용프로그램
  - 근데 응용프로그램은 유저레벨이니까 유저레벨 함수만으론 많은 기능 구현 어려움
  - 그래서 커널이 제공하는 함수들 도움좀 받아보자!! 대신 커널 모드여야 함!! 우저모드에서 시스템 콜하면? 트랩발생
   
 ### 📌시스템콜 처리방식
 - 1. 사용자프로세스가 시스템콜을 요청하면 사용자 모드->커널모드 돼서 제어가 커널로 넘어옴
 - 2. 커널은 내부적으로 서비스 루틴 호출
 - 3. 서비스루틴 처리 끝나면 커널모드->사용자 모드로 다시 전환!

 ### 📌어케 호출?   
 - 쉘(Shell)에서 운영체제 기능 호출
 - 쉘은 사용자가 운영체제 기능과 서비스를 조작할 수 있도록 인터페이스를 제공하는 프로그램. 2가지 환경 제공
   - 터미널환경
   - GUI환경
   
 ### 📌종류
 - fork( ), exec( ), wait( )와 같은 것들은 Process 생성과 제어를 위한 System call임.
   - `fork`
     - 새로운 Process 를 생성할때 사용
     - fork 함수는 새로운 프로세스를 생성함→새 프로세스는 child process 라고 함
     - fork 함수를 호출한 프로세스는 parent process 가 됨
     - child process는 PCB중 PID바뀜
     - 장점
        - 빠르다: 부모 프로세스 복사=프로세스 생성 속도 빠름 
        - 시스템 관리 효율적: 자식 프로세스 종료하면? 메모리 정리 등을 부모 프로세스한테 맡김
     - fork 함수 실행시 처리 과정
        - 1. fork 함수 호출
        - 2. 새로운 프로세스(자식 프로세스)생성
        - 3. fork 함수로 생성한 자식 프로세스의 메모리 공간은 부모 프로세스의 메모리 공간을 그대로 복사해 만듦
        - 4. 이 함수는 부모 프로세스에는 자식 프로세스의 PID를 리턴하고, 자식 프로세스에는 0을 리턴함
     - fork 함수가 리턴하면 부모 프로세스와 자식 프로세스가 동시에 동작하는데, 어느 프로세스가 먼저 실행될지는 알수 없음
   - `wait`
     - child의 프로세스가 종료될 때까지 기다리는 작업
     - wait를 통해서, child의 실행이 끝날 때까지 기다려줌. parent가 먼저 실행되더라도, wait ()는 child가 끝나기 전에는 return하지 않으므로, 반드시 child가 먼저 실행됨.
   - `exec`
     - 단순 fork는 동일한 프로세스의 내용을 여러 번 동작할 때 사용함.
     - child에서는 parent와 다른 동작을 하고 싶을 때=exec()를 실행하면 현재의 프로세스가 완전히 다른 프로세스로 전환
     - PCB를 재활용하기 위해서이다
     - PCB중 프로세스 구분자, 부모 프로세스 구분자, 자식 프로세스 구분자, 메모리 관련 사항을 제외한 프로그램 카운터 레지스터 값을 비롯한 각종 레지스터와 사용한 파일정보가 모두 리셋됨
     - 이미 만들어진 PCB,메모리 영역, 부모-자식 관계를 그대로 사용할 수 있어 편리
     - 새로운 코드 영역만 가져오면 되기 때문에 운영체제의 작업이 수월하다
   
   
 ### 👉fork() 와 exec() 가 사용되는 경우를 설명   
   fork()를 사용하는 경우는 동일한 프로세스의 내용을 여러번 동작시킬 때 입니다.

exec()를 사용하는 경우는 child 에서는 parent 와 다른 동작을 하고 싶을 때입니다.

→추가 질문 fork()를 사용할 경우 부모 프로세스와 자식 프로세스중 어떤것이 먼저 실행되나요?

→답변: fork()를 사용할 경우 두 프로세스의 실행 순서는 스케줄러가 관리하며, 부모 프로세스와 자식 프로세스의 순서는 보장되지 않습니다.

→추가 질문: 자식 프로세스를 먼저 실행하고 싶을때, **순서를 보장해줄 수 있는 방법**이 있나요?

→ 답변: wait() 시스템 콜을 사용하면 됩니다.
   
 [click](https://www.notion.so/System-Call-2fff05f679b14bff86ef6fd413d0577a)  
 
 ***
   
 </details>


<details>
   <summary><strong><span style="border-bottom:0.05em solid">스택을 스레드마다 독립적으로 할당하는 이유는 무엇인가요?</span></strong></summary>

  <br> 
   
- 스택은 함수의 **인자, 지역변수, 복귀 주소값**을 저장하기 위해 사용되는 메모리 공간입니다. 
- 스택 메모리 공간이 독립적이라는 것은 **독립적인 함수 호출 즉 독립적인 실행흐름이 가능함을 의미**
- 따라서 스레드의 정의에 따라 독립적인 실행 흐름을 추가하기 위한 조건으로 스레드마다 스택을 할당해줌
   
 ***  
   
</details>


<details>
   <summary><strong><span style="border-bottom:0.05em solid">PC 레지스터를 스레드마다 독립적으로 할당하는 이유는 뭘까?</span></strong></summary>

</br> 
   
- PC 값은 **스레드가 명령어의 어디까지 수행했는지**를 나타내게 된다. 
- 스레드는 CPU를 할당받았다가 스케줄러에 의해 다시 선점당한다. 
- 그렇기 때문에 명령어가 **연속적으로 수행되지 못하고 어느 부분까지 수행했는지 기억**할 필요가 있다. 
- 따라서 PC 레지스터를 독립적으로 할당해 복귀 후 다시 사용될 상태값들을 저장해야 한다
   
</details>

***


<details>
   <summary><strong><span style="border-bottom:0.05em solid">교착상태가 발생하기 위한 조건은?</span></strong></summary>
<hr>
   <p>4가지 중 하나라도 성립하지 않으면 데드락은 발생하지 않습니다.</p>
   <ol>
      <li><strong>상호 배제(Mutual exclusion) : </strong>자원은 한번에 한 프로세스만 사용할 수 있음</li>
   </ol>
   <ol>
      <li><strong>점유 대기(Hold and wait) : </strong>최소한 하나의 자원을 점유하고 있으면서 다른 프로세스에 할당되어 사용하고 있는 자원을 추가로 점유하기 위해 대기하는 프로세스가 존재해야 함</li>
   </ol>
   <ol>
      <li><strong>비선점(No preemption) : </strong>다른 프로세스에 할당된 자원은 사용이 끝날 때까지 강제로 빼앗을 수 없음</li>
   </ol>
   <ol>
      <li><strong>순환 대기(Circular wait) : </strong>프로세스의 집합에서 순환 형태로 자원을 대기하고 있어야 함</li>
   </ol>

<hr>
</details>


<details>
   <summary><span style="border-bottom:0.05em solid"><strong>교착상태의 해결법은 무엇인가요?</strong></span></summary>
<hr>
   <ol>
      <li>
         <strong>예방(prevention)</strong>
         <p>교착 상태 발생 조건 중 하나를 제거하면서 해결한다 (자원 낭비 엄청 심함)</p>
         <ul>
            <li>상호배제 부정 : 여러 프로세스가 공유 자원 사용</li>
         </ul>
         <ul>
            <li>점유대기 부정 : 프로세스 실행전 모든 자원을 할당</li>
         </ul>
         <ul>
            <li>비선점 부정 : 자원 점유 중인 프로세스가 다른 자원을 요구할 때 가진 자원 반납</li>
         </ul>
         <ul>
            <li>순환대기 부정 : 자원에 고유번호 할당 후 순서대로 자원 요구</li>
         </ul>
      </li>
   </ol>
   <ol>
      <li>
         <strong>회피(avoidance) - </strong>교착 상태 발생 시 피해나가는 방법
         <p>은행원 알고리즘(Banker&#x27;s Algorithm)
         <div class="indented">
            <p>은행에서 모든 고객의 요구가 충족되도록 현금을 할당하는데서 유래함</p>
            <p>프로세스가 자원을 요구할 때, 시스템은 자원을 할당한 후에도 안정 상태로 남아있으면 자원할당, 아니면 할당을 거부하고 다른 프로세스 들이 자원을 해지할때까지 대기하는 방법</p>
         </div>
         </p>
      </li>
   </ol>
   <ol>
      <li>
         <strong>탐지(Detection) &amp; 회복</strong>
         <p>은행원 알고리즘과 유사한 방식 vs 자원 할당 그래프를 통해 교착 상태를 탐지함</p>
         <p>자원 요청 시, 탐지 알고리즘을 실행시켜 그에 대한 오버헤드 발생함</p>
      </li>
   </ol>
   <ol>
      <li>
         <strong>회복(Recovery) - </strong>교착 상태 일으킨 프로세스를 종료하거나, 할당된 자원을 해제시켜 회복시키는 방법
         <p><strong>프로세스 종료 방법</strong></p>
         <ul>
            <li>교착 상태의 프로세스를 모두 중지</li>
         </ul>
         <ul>
            <li>교착 상태가 제거될 때까지 하나씩 프로세스 중지</li>
         </ul>
         <p><strong>자원 선점 방법</strong></p>
         <ul>
            <li>교착 상태의 프로세스가 점유하고 있는 자원을 선점해 다른 프로세스에게 할당 (해당 프로세스 일시정지 시킴)</li>
         </ul>
         <ul>
            <li>우선 순위가 낮은 프로세스나 수행 횟수 적은 프로세스 위주로 프로세스 자원 선점</li>
         </ul>
      </li>
   </ol>
   <ol>
      <li><strong>무시</strong></li>
   </ol>

<hr>
</details>


<details>
   <summary><span style="border-bottom:0.05em solid"><strong>회피 기법인 은행원 알고리즘이 뭔지 설명해보세요.</strong></span></summary>
<hr>
   <p>은행원 알고리즘은 은행에서 현금을 할당하는 것에서 유래한 알고리즘입니다.</p>
   <p>프로세스가 자원을 요구할때 자원을 할당한 후에도 안정 상태이면 자원을 할당하고, 그렇지 않으면 다른 자원이 해제될때까지 대기했다가 자원을 할당합니다.</p>

<hr>
</details>


<details>
   <summary><span style="border-bottom:0.05em solid"><strong>은행원 알고리즘의 단점</strong></span></summary>
<hr>
   <ul>
      <li>할당할 수 있는 자원수가 일정 해야함</li>
   </ul>
   <ul>
      <li>항상 불안전 상태를 방지해야 하므로 <strong>자원 이용도가 낮다</strong></li>
   </ul>
   <ul>
      <li><strong>최대 자원 요구량</strong>을 미리 알아야 한다.</li>
   </ul>
   <ul>
      <li>프로세스들은 유한한 시간 안에 자원을 반납해야 한다.</li>
   </ul>

<hr>
</details>


<details>
   <summary><span style="border-bottom:0.05em solid"><strong>기아상태를 설명하는 식사하는 철학자 문제에 대해 설명해보세요.</strong></span></summary>
<hr>
   <ol>
      <li>일정 시간 생각을 한다.</li>
   </ol>
   <ol>
      <li>왼쪽 포크가 사용 가능해질 때까지 대기한다. 만약 사용 가능하다면 집어든다.</li>
   </ol>
   <ol>
      <li>오른쪽 포크가 사용 가능해질 때까지 대기한다. 만약 사용 가능하다면 집어든다.</li>
   </ol>
   <ol>
      <li>양쪽의 포크를 잡으면 일정 시간만큼 식사를 한다.</li>
   </ol>
   <ol>
      <li>오른쪽 포크를 내려놓는다.</li>
   </ol>
   <ol>
      <li>왼쪽 포크를 내려놓는다.</li>
   </ol>
   <ol>
      <li>다시 1번으로 돌아간다.</li>
   </ol>

<hr>
</details>


<details>
   <summary><span style="border-bottom:0.05em solid"><strong>철학자 문제 교착상태 조건 성립 조건</strong></span></summary>
<hr>
   <p><strong>상호 배제 -&gt; </strong>젓가락은 한 번에 한 철학자만 사용할 수 있습니다.</p>
   <p><strong>점유와 대기 -&gt;</strong> 왼쪽 젓가락을 점유하면서 오른쪽 젓가락을 대기합니다.</p>
   <p><strong>비선점 -&gt; </strong>이미 누군가가 집어 든 젓가락을 강제로 뺏을 수 없습니다.</p>
   <p><strong>환형 대기 -&gt; </strong>모든 철학자들이 오른쪽에 앉은 철학자가 젓가락을 놓기를 기다립니다.</p>

<hr>
</details>


<details>
   <summary><span style="border-bottom:0.05em solid"><strong>식사하는 철학자 문제 해결책</strong></span></summary>
<hr>
   <ol>
      <li>모두 젓가락을 내려두고 랜덤시간동안 기다린 다음 식사 (기아현상이 발생할 수 있는 가능성이 남아 있음)</li>
   </ol>
   <ol>
      <li>
         뮤텍스 - <mark class="highlight-gray">(화장실이 하나밖에 없는 식당)</mark>
         <p>공유된 자원의 데이터를 여러 쓰레드가 접근하는 것을 막는 것</p>
         <p>식사할 수 있는 상황을 하나의 key로 관리</p>
         <p>오직 하나의 쓰레드만이 동일한 시점에 뮤텍스를 얻어 임계 영역(Critical Section)에 들어올 수 있다. 그리고 오직 이 쓰레드만이 임계 영역에서 나갈 때 뮤텍스를 해제할 수 있다.</p>
         <p>Critical Section을 가진 쓰레드들의 Running tme이 서로 겹치지 않게 각각 단독으로 실행되게 하는 기술</p>
      </li>
   </ol>
   <ol>
      <li>
         세마포어 -<mark class="highlight-gray"> (화장실이 여러개인 식당)</mark>
         <p>공유된 자원의 데이터를 여러 프로세스가 접근하는 것을 막는 것</p>
         <p>Signaling mechanism. 현재 공유자원에 접근할 수 있는 쓰레드, 프로세스의 수를 나타내는 값을 두어 상호배제를 달성하는 기법</p>
         <p>락을 걸지 않은 쓰레드도 Signal을 보내 락을 해제할 수 있다는</p>
      </li>
   </ol>

<hr>
</details>

***


<details>
   <summary><span style="border-bottom:0.05em solid"><strong>경쟁 상태(Race Condition)란 무엇인가요?</strong></span></summary>

 - 여러 스레드 or 프로세스가 한정된 공유 자원에 동시에(concurruntly) 접근하는 경우
- 경쟁상태는 **데이터의 불일치(inconsistency)** 문제 를 야기할 수 있다
- 경쟁 상태를 다루기 위해서는 **동기화=하나의 자원을 한 순간에 하나의 프로세스만이 이용하도록 제어** 되어야 함  
   
***
   
</details>


<details>
   <summary><span style="border-bottom:0.05em solid"><strong>경쟁상태가 발생하는 경우</strong></span></summary>

- 주로, user mode일 때 보다(일반 프로세스가 cpu를 잡고 사용 할 경우) 커널모드일 때 race condition   이 일어난다
- 프로세스간에는 주소 공간이 독립적이지만 커널모드에서는, 커널에 있는 자원을 여러 프로세스가 공유할 수 있기 때문 

1. process가 system call을 해서, kernel mode로 수행중인데 context switch가 일어나는 경우   
- 문제점
  - 프로세스 a가 커널모드로 작업을 수행하면서, count 변수의 값을 읽어오고 증가시키려고 하는 와중에 context switch가 발생함.  프로세스 b에서도 count 변수의 값을 변경하게 됨. 
  - 이 때, 프로세스 b에 의해 변경된 count 값은 반영되지 않게 된다. 
  - 왜? 이미 커널에서는 (프로세스 a의 작업을 할 때) 변경되기 이전 count의 값을 가져온 상태이기 때문
- 해결 방안
  - 커널모드에서 수행 중일 때는 cpu를 뺏지 않는다 → 커널 모드에서 user 모드로 바뀔 때 cpu를 빼앗음
   
2. 커널모드로 작업 중에, 인터럽트가 발생한 경우   
- 문제점
   - 커널모드에서 데이터를 로드하여 작업을 수행하다가 인터럽트가 발생하여 같은 데이터를 조작하는 경우
- 해결방안
   - 커널에서 공유 변수에 접근하고 있을 때에는, 인터럽트를 받지 아니함

3. 멀티 프로세서 환경에서 공유 메모리 내의 커널 데이터에 접근할 때
- 문제점 
   - 멀티 프로세서 환경에서 2개의 CPU가 동시에 커널 내부의 공유 데이터에 접근하여 조작하는 경우
- 해결법 
   - 커널 내부에 있는 각 공유 데이터에 접근할 때마다, 그 데이터에 대한 lock/unlock을 하는 방법   
   
*** 
   
</details>




<details>
   <summary><span style="border-bottom:0.05em solid"><strong>경쟁상태 해결방법은 무엇이 있나요?</strong></span></summary>
- 상호배제
- 동기화
   - 세마포어
   - 모니터
   - 락

<hr>
</details>

***

<details>
   <summary><span style="border-bottom:0.05em solid"><strong>🦑Mutex vs Semaphore</strong></span></summary>

- 세마포어와 뮤텍스는 동기화 문제를 해결하기 위한 방법입니다. 여러 프로세스가 공유자원에 접근할때, 한 프로세스가 크리티컬 섹션에서 수행중이라면 다른 프로세스는 자신의 크리티컬 섹션에 들어가지 못하게 해야합니다.

- 세마포어에는 P연산과 V연산이 있습니다. P연산은 자원을 할당하는 연산이고 V연산은 자원을 해제하는 연산입니다. 크리티컬 섹션에 들어가기 전 세마포어를 통해 자원에 접근가능한지 확인을 하며 동기화문제를 해결합니다. 공유 자원에 프로세스들이 최대 허용치만큼 접근할 수 있음

- 뮤텍스는 이진 세마포어의 일종으로 자원에 lock을 걸면서 동기화 문제를 해결합니다. 상호 배제 개념을 이용하며 크리티컬 섹션을 가진 스레드들이 각각 단독으로 실행되게 하는 기술입니다.   
   
[click](https://www.notion.so/38500ed280374fe58b00d1e46485b737?v=99975506109e452c8beae36d9c4166be&p=bb08f310a442430b92fba6cafd38de5b&pm=s)   
      
   
</details>

<details>
   <summary><span style="border-bottom:0.05em solid"><strong>🦑동기와 비동기, 블로킹과 넌블로킹의 차이는 무엇인가요?</strong></span></summary>
<hr>
   <p>동기/비동기 - 작업 주체 여러개</p>
   <p>블로킹/논블로킹 - 작업이 여러개</p>
   <p></p>
   <p>동기 : 시작과 종료를 동시에 하거나, 하나가 끝나면 다른 하나가 시작하는 경우</p>
   <p>비동기 : 별도의 시작/종료를 가짐</p>
   <p>블로킹 : 작업을 하다가 다른 작업이 완료될때까지 기다렸다가 다시 수행</p>
   <p>넌블로킹 : 다른 작업과 관련없이 자기 작업 계속함</p>

[click](https://www.notion.so/38500ed280374fe58b00d1e46485b737?v=99975506109e452c8beae36d9c4166be&p=bd1a360e19254778b9fc8d2439675cca&pm=s)   
   
<hr>
</details>


<details>
   <summary><span style="border-bottom:0.05em solid"><strong>🦑IPC란 무엇인가요?</strong></span></summary>
<hr>
   <p>IPC는 Inter-Process Communication의 약자로 프로세스간 통신을 의미합니다. 프로세스는 커널이 제공하는 IPC 설비를 이용해 프로세스간 통신을 할 수 있습니다. </p>
   <p>IPC설비의 종류는 여섯 가지가 있습니다. </p>
   <p>첫번째는, PIPE (익명 파이프) 입니다. PIPE는 두 프로세스간 파이프를 연결해서 통신을 하는 방식입니다. 여기서 한 프로세스는 쓰기만 가능하고 다른 프로세스는 읽기만 가능하다는 특징이 있습니다. 한쪽 방향으로만 통신이 가능하기 때문에 반이중 통신이라고 부르기도 합니다. PIPE는 간단하게 사용할 수 있다는 장점이 있습니다.</p>
   <p>두번째는, Named PIPE (FIFO) 입니다. PIPE는 통신하는 프로세스가 명확할 경우 사용하는 반면, Named PIPE는 전혀 모르는 사이의 프로세스들의 통신에 사용합니다. 익명 PIPE는 부모가 동일한 프로세스들 사이에서만 통신이 가능하지만 Named PIPE는 부모 프로세스에 상관없이 프로세스들 사이의 통신을 할 수 있다는 점이 특징입니다. 이는 프로세스 통신을 위해 mkfifo함수를 이용해 파일을 생성하기 때문에 가능합니다. 하지만, 익명 PIPE와 동일하게 동시에 읽기/쓰기가 불가능 합니다. 이는 두개의 파일을 읽기전용, 쓰기전용으로 만들어서 해결할 수 있습니다. 전이중 통신을 위해서는 두 개의 fifo 파일을 만들어서 사용해야 합니다.</p>
   <p>세번째는, 메세지 큐 입니다. 메세지 큐는 선입선출의 형태로 통신이 이루어지는 점에서 Named PIPE와 동일합니다. 차이점은 Named PIPE가 데이터의 흐름이라면 메세지 큐는 메모리 공간이라는 점입니다. 이는 여러개의 프로세스가 메세지 큐의 데이터에 접근할 수 있음을 의미합니다.</p>
   <p>네번째는, 공유메모리 입니다. 앞서 PIPE, Named PIPE, 메세지 큐가 통신을 이용해 데이터를 주고받는다면, 공유메모리는 프로세스간 메모리 영역을 공유해서 사용할 수 있도록 지원합니다. 프로세스가 공유 메모리 할당을 커널에 요청하면 커널은 해당 프로세스에 메모리 공간을 할당해줍니다. 이후 어떤 프로세스건 해당 메모리영역에 접근할 수 있습니다. 공유 메모리는 곧바로 메모리에 접근할 수 있기 때문에 IPC 방식 중 속도가 제일 빠릅니다.</p>
   <p>다섯번째는, 메모리 맵 입니다. 메모리 맵은 공유 메모리와 메모리를 공유한다는 점은 동일합니다. 하지만, 현재 열려져 있는 파일을 공유하는 점에서 차이가 있습니다. 열린 파일이 메모리에 올라가있으면 다른 프로세스가 해당 파일을 사용할 때 또다시 파일을 열지않고 공유한 상태로 사용하는 것이 더 효율적입니다.</p>
   <p>여섯번째는, 소켓입니다. 소켓은 소켓을 만들어 통신하는 방법입니다. 소켓 통신은 데이터 교환을 위해 양쪽 PC에서 각각 임의의 포트를 정하고 해당 포트 간의 대화를 통해 데이터를 주고받는 방식입니다. 이 때 각각 PC의 프로세스는 임의의 PORT를 맡아 데이터를 송수신 합니다.
   
 [click](https://www.notion.so/38500ed280374fe58b00d1e46485b737?v=99975506109e452c8beae36d9c4166be&p=340019d9a4f44e19b584cc9e7b23ec49&pm=s)
      
   </p>

   
<hr>
</details>


<details>
   <summary><span style="border-bottom:0.05em solid"><strong>child process와 zombi process에 대해 설명해 보시오. (고아/좀비)</strong></span></summary>
<hr>
   <p>자식 프로세스 : fork로 자식프로세스를 만든 상태. 부모의 데이터,힙,스택, PCB 복사</p>
   <p>좀비 프로세스 : 프로세스가 종료됐는데 메모리상에 정보가 남아있는 상태, 부모가 wait로 보고받지 못함</p>
   <p>고아 프로세스 : 부모 프로세스가 먼저 종료돼서 부모 프로세스를 잃은 프로세스, init이 자식프로세스 회수함</p>

<hr>
</details>


# 메모리<a name = "outline"></a>

<details>
   <summary><span style="border-bottom:0.05em solid"><strong>메모리 관리자=MMU란?</strong></span></summary>

 - `정의`
   -  MMU(메모리 관리 유닛)
     - CPU가 메모리에 접근하는 것을 관리하는 컴퓨터 하드웨어 부품이다. 
     - 가상 메모리 주소를 실제 메모리 주소로 변환  
     - 가져오기 / 배치 / 재배치 작업을 한다
   
</details>

### 1️⃣가져오기 정책<a name = "outline"></a>

<details>
   <summary><span style="border-bottom:0.05em solid"><strong>Demand Paging=요구페이징 이란?</strong></span></summary>

 - `정의`
    - 프로세스의 모든 페이지를 메모리에 올려두지 않고, 필요할 때=사용자가 요구할 때 메모리에 올리는 것
    EX) 포토샵 본 프로그램은 메모리에 올려두고 외부필터는 사용자가 필요할 때 메모리로 가져오기
- `장점`
    - 메모리 절약
    - 메모리 효율 관리
    - 응답 속도 향상
   
</details>


<details>
   <summary><span style="border-bottom:0.05em solid"><strong>미리 가져오기?</strong></span></summary>

 - `정의`
    - 요구페이징과 반대로 앞으로 필요할 것이라고 예상되는 페이지를 미리 가져오기
    EX) 캐시 메모리
- `장점`
    - 빠르게 사용가능
   
</details>

### 2️⃣배치정책<a name = "outline"></a>

<details>
   <summary><span style="border-bottom:0.05em solid"><strong>메모리 관리 기법</strong></span></summary>
   
![Untitled](https://user-images.githubusercontent.com/89257243/187341137-ffd30a6e-7658-4e22-9138-5a4f99657f3e.png)
- `연속 메모리 할당` : 프로그램 전체가 하나의 커다란 공간에 연속적으로 할당되어야 함
    - `가변분할`
        - 파티션이 동적으로 생성됨 → 처음에 몇개의 고정된 분할을 만들어 두는 것 아님.
        - 각 프로세스는 자신의 크기와 일치하는 파티션에 들어가게 됨
        - **외부단편화** 발생 가능
    - `고정분할`
        - 물리적 메모리를 몇개의 영구적 분할로 나눔
        - 분할당 하나의 프로그램을 적재
        - **내부단편화** 발생 가능
   
![Untitled (1)](https://user-images.githubusercontent.com/89257243/187342985-3315d689-c35e-4590-87a9-aff931b1f94a.png)
   
   
- `불연속 메모리 할당`: 프로그램의 일부가 서로 다른 주소 공간에 할당될 수 있는 기법
     - `단순 페이징 기법` => 페이지 고정사이즈 = 고정분할
      - fragmentation(단편화) 문제를 해결하기 위해 등장한 방법 
      - 각 프로세스를 동일한 사이즈의 page(메모리 단위)로 나누어 분할 관리하는 기법
      - 외부 단편화 발생 안함
      - 내부 단편화 발생 가능

    - `단순 세그먼테이션 기법` =>프로세스를 물리적 단위인 페이지가 아닌 논리적 단위인 세그먼트로 분할 = 가변분할
     -  파티션이 동적으로 생성됨 → 처음에 몇개의 고정된 분할을 만들어 두는 것 아님.
     - 각 프로세스는 자신의 크기와 일치하는 파티션에 들어가게 됨
     - 외부단편화 발생 가능
    
[👉click](https://www.notion.so/56f34c8f18454a9182cef43df1b857cb)
   
</details>



<details>
   <summary><span style="border-bottom:0.05em solid"><strong>메모리의 First Fit, Best Fit, Worst Fit에 대해서 설명해 보시오.</strong></span></summary>

- 가변 분할 방식에서, 프로그램을 넣을 적절한 위치(hole = fragment)를 찾는 문제

- 최초(First fit) : 적재가능 공간 순서대로 찾다가 첫번째로 발경한 공간에 배치 -> 탐색필요X
- 최적(Best fit) : 메모리 처음부터 검사해서 외부단편화 최소 공간에 프로세스 배치 -> 딱맞으면 단편화X but 남은 공간 작아서 쓸모X
- 최악(Worst Fit) : 메모리의 처음부터 검사해서 크기가 가장 큰 공간에 프로세스 배치 -> 배치 후 남는 공간 커서 쓸모O but 이후엔 최적배치 문제와 동일
💡 **어떤 방법을 사용하든, fragmentation이 일어나는 건 막을 수 없음 → 페이징(paging) 등장**
   
</aside>
   
</details>

<details>
   <summary><span style="border-bottom:0.05em solid"><strong>내부단편화 외부단편화</strong></span></summary>
   
- 외부단편화
    - 물리주소(물리주소 0번지부터 시작하는 메모리 관리자 입장)에 빈공간보다 큰 프로세스 들어오면 작은 빈공간엔 메모리 배정 불가. 즉 사용 못하는 빈공간 생기는 현상
    - 프로세스 외부에 단편화가 발생한다는 의미로 외부단편화
- 내부단편화
    - 메모리 조각보다 작은 프로세스를 배치 후 낭비되는 메모리 공간 발생하는 현상
    - 같은 크기로 나뉜 메모리 공간 내부에 단편화가 발생한다는 의미로 내부단편화
   
</details>

***

<details>
   <summary><span style="border-bottom:0.05em solid"><strong>가상 메모리(Virtual Memory)란?</strong></span></summary>
 
   ![KakaoTalk_20220830_163319464](https://user-images.githubusercontent.com/89257243/187377710-b750e10d-af5d-4891-85e0-f7f17bba119d.jpg)

- `등장배경` => 물리메모리 크기를 신경쓰고싶지 않은 프로세스
 - 컴퓨터마다 물리메모리의 크기가 다름
   -운영체제가 물리메모리 크기에만 의존한다면?
     - 2GB메모리에서 동작하는 프로그램 동작 안하거나 = 프로그램을 실행할때 불필요하게 전체의 프로그램이 메모리에 올라와 있어야 하는게 아니라는 것
     - 메모리에 맞는 응용 프로그램만 개발해야함 = 프로그램의 용량이 커지는 것에 비해 메모리 용량을 크게 한다는 것은 많은 어려움
     - **물리메모리의 크기와 상관없이 프로세스에 커다린 메모리 공간=가상공간을 제공해서 프로세스는 물리 메모리크기따위 신경쓰지않고 메모리 마음대로 사용**
     - 사용자는, 메모리로서 실제 존재하지는 않지만 메모리로써의 역할을 하는 가상의 메모리를 갖는것
     - but, 가상메모리에 수용된 프로그램이 실행될 때는 실제 메모리를 필요로 하게 되는 것
   
- `가상메모리는 어떻게 이론적으로 크기가 무한대지?` => 부족한 부분 스왑영역으로 보충해서
   - 메모리 관리자가 물리메모리에서 부족한 부분을 스왑영역(하드디스크에 존재하지만  MMU 가 관리하는 메모리 일부)으로 보충
   - 모든 프로세스는 물리 메모리와 별개로 자신이 메모리에 어느 위치에 있는지 상관없이 0번지부터 시작하는 연속된 메모리 공간을 가짐
   
- 가상메모리에 있는 프로그램이 실행될때 어떻게 실제 메모리로 옮겨지는가?
   - 가상메모리에 있던 프로그램이 실제로 실행될떄는 물리 메모리가 필요
   - `매핑`: 가상메모리에 있는 프로그램을 실제 메모리로 옮겨주는 것 =? 메모리 관리자 역할
   - `매핑 테이블`: 가상주소가 물리메모리의 어느 위치에 있는지 알 수 있도록 정리한 표 
     - 페이징기법에선 페이지 매핑 테이블, 세그먼테이션기법에선 세그먼테이션 매핑 테이블 
     - 프로세스마다 매핑 테이블 하나씩 있음 / 빠른 접근 필요->메모리의 운영체제 영역 적재
   
   
</details>

<details>
   <summary><span style="border-bottom:0.05em solid"><strong>가상 메모리에서의 배치정책?</strong></span></summary>

 - `페이징 기법`
    - 고정분할 방식을 이용한 가상 메모리 관리 기법으로, 물리메모리를 같은 크기로 나누어 사용
    - 단순 페이징과 비교해 프로세스 페이지 전부를 로드시킬 필요X
    - 고정분할이니까 외부 단편화 X
    - `페이지` : 가상주소의 분할된 각 영역을 부르는 이름
    - `프레임` : 물리주소의 분할된 각 영역을 부르는 이름
   
 - `세그먼테이션 기법`
    - 가변분할 방식을 이용한 가상 메모리 관리 기법으로, 물리메모리를 프로세스 크기에 따라 가변적으로 나누어 사용
    - 단순 세그먼테이션과 비교해 필요하지 않은 세그먼트를 전부 로드시킬 필요X
    - 가변분할이니까 내부 단편화 X
   
</details>

<details>
   <summary><span style="border-bottom:0.05em solid"><strong>가상 메모리를 사용할 시 장단점은?</strong></span></summary>

- `장점`
   - 실제 메모리(RAM)크기 보다 더 큰 공간을 사용할 수 있음
   - 프로세스는 물리 메모리 주소 공간을 알 필요가 없어짐
   
- `단점`
   - 전반적인 속도가 느려질 수 있다: 물리메모리로 바로 올라가서 실행되는 것보다 속도가 느릴 수 있다
   
</details>


### 3️⃣재배치 정책<a name = "outline"></a>

<details>
   <summary><span style="border-bottom:0.05em solid"><strong>페이지교체?</strong></span></summary>

- `페이지 부재`
   - 프로세스가 페이지 요청했는데 메모리에 없는 상황
   
- `재배치 정책`
   - 프로세스가 페이지 요청->페이지 부재->엥 메모리 꽉참->어떤 페이지 스왑영역으로 보낼지 결정하자 = 재배치 정책
 
 - `페이지 교체 알고리즘`
   - 스왑영역으로 보낼 페이지 결정하는 알고리즘
   - 메모리에서 앞으로 사용할 가능성이 적은 페이지를 대상 페이지로 선정해서 페이지 부재 줄이고 시스템 성능 향상하자
    
 
</details>


<details>
   <summary><span style="border-bottom:0.05em solid"><strong>🦑페이지 교체 알고리즘 종류에는 어떤 것들이 있나요?</strong></span></summary>

- OPT : 최적 교체. 앞으로 가장 오랫동안 사용하지 않을 페이지 교체 (실현 가능성 희박)
- FIFO : 메모리가 할당된 순서대로 페이지를 교체
- LRU : 최근에 가장 오랫동안 사용하지 않은 페이지를 교체
- LFU : 사용 빈도가 가장 적은 페이지를 교체
- NUR : 최근에 사용하지 않은 페이지를 교체


</details>


***

<details>
   <summary><span style="border-bottom:0.05em solid"><strong>메모리 관리</strong></span></summary>
<hr>
각각의 프로세스는 독립된 메모리 공간을 갖고, 운영체제 혹은 다른 프로세스의 메모리 공간에 접근할 수 없는 제한이 걸려있다. 단지, 운영체제 만이 운영체제 메모리 영역과 사용자 메모리 영역의 접근에 영향을 받지 않는다. 따라서 메모리에는 적절하게 관리되어 사용되야 한다.
<hr>
</details>

<details>
   <summary><span style="border-bottom:0.05em solid"><strong>메모리 구조의 순서가 어떻게 되는가? CPU에서 가까운 순으로 말해보시오.</strong></span></summary>
<hr>
   <p>레지스터, 캐시, 주기억장치, 보조기억장치 순서입니다.</p>
   <p>CPU는 프로그램 실행 시 먼저 레지스터에 필요한 데이터가 있는지 확인합니다.</p>
   <p>레지스터에 필요한 데이터가 존재하지 않는다면 캐시를, 캐시에도 없다면 주기억장치를, 주기억장치에도 없다면 보조기억장치를 확인하며 필요한 데이터를 적재합니다.</p>
   <p>https://popcorntree.tistory.com/68</a></p>
   <figure/></a></figure>
   <ul>
      <li><strong>레지스터</strong> : CPU 내에 존재하는 메모리로 빠르고 작다.</li>
   </ul>
   <ul>
      <li><strong>캐시</strong> : CPU와 주기억장치 사이에서 중간 저장소 역할을 함. Locality 특성 이용</li>
   </ul>
   <ul>
      <li><strong>주기억장치</strong> : 현재 수행되는 프로그램과 데이터 저장</li>
   </ul>
   <ul>
      <li><strong>보조기억장치</strong> : 용량이 크나 느리다.</li>
   </ul>

<hr>
</details>



<details>
   <summary><span style="border-bottom:0.05em solid"><strong>Cache Memory의 역할은 무엇인가</strong></span></summary>
<hr>
   <p>캐시 메모리는 CPU와 메모리 사이의 속도 차이를 완화하기 위한 역할을 합니다. 캐시는 메모리의 데이터를 미리 가져와 저장해두는 임시 장소로 앞으로 사용될 것으로 예상되는 데이터를 미리 저장해 놓습니다. </p>

<hr>
</details>


<details>
   <summary><span style="border-bottom:0.05em solid"><strong>Caching Locality와 Cache Hit Ratio에 대해 설명하시오</strong></span></summary>
<hr>
   <p><strong>캐시 적중률</strong>은 CPU가 사용할 데이터를 캐시에서 탐색 했을 때, 원하는 데이터가 캐시에 존재할 확률을 의미합니다. </p>
   <p><strong>캐시 적중률</strong>을 높이기 위해서는 캐시 메모리의 크기를 늘리는 방법과 앞으로 많이 사용될 데이터를 캐시에 저장하는 방법이 있습니다. </p>
   <p>앞으로 많이 사용될 데이터를 저장하기 위해서는 <strong>캐시 지역성</strong>을 이용할 수 있습니다. 캐시 지역성은 현재 사용하고 있는 메모리 위치에서 가까운 데이터를 사용할 확률이 높다는 개념입니다. 따라서, 현재 접근하고 있는 메모리 근처의 값들을 캐시에 저장해놓는다면 캐시 적중률을 높일 수 있습니다.</p>
   
캐시 메모리는 CPU와 메모리 사이의 속도 차이를 완화하기 위한 역할 을 한다.
캐시는 메모리의 데이터를 미리 가져와 저장해두는 임시 장소로 앞으로 사용될 것으로 예상되는 데이터를 미리 저장해 놓는다.
즉, 프로세서(CPU) 가까이에 위치하면서 빈번하게 사용되는 데이터를 놔두는 장소 이다.
이러한 역할을 수행하기 위해서는 CPU가 어떤 데이터를 원할 것인가를 어느정도 예측하고 있어야 한다.
캐시의 성능은 작은 용량의 캐시 메모리에 CPU가 이후에 참조할, 쓸모 있는 정보가 어느정도 들어있느냐에 따라 좌우되기 때문이다.
적중률(Hit rate)를 극대화 시키기 위해 데이터 지역성(Locality)의 원리를 사용한다.

시간 지역성
최근에 참조된 주소의 내용은 곧 다음에 다시 참조되는 특성
공간 지역성
참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성
이런 지역성을 이용해 현재 접근하고 있는 메모리의 근처 값들을 캐시에 저장해 놓는다면 캐시 적중률을 높일 수 있다.
   
<hr>
</details>


<details>
   <summary><span style="border-bottom:0.05em solid"><strong>Call Stack에 대해 설명하시오</strong></span></summary>
<hr>
   <p>컴퓨터 프로그램에서 현재 실행 중인 서브루틴에 관한 정보를 저장하는 스택 자료구조</p>

<hr>
</details>

<details>
   <summary><span style="border-bottom:0.05em solid"><strong>Heap과 Stack의 장단점 비교 (속도, 크기 등)</strong></span></summary>
<hr>
   <p><strong>스택</strong> : 빠르다, 스택 크기 제한</p>
   <p><strong>힙</strong> : 메모리 크기 제한 없음, 메모리를 직접 관리해야함, 상대적으로 느림</p>

<hr>
</details>


<details>
   <summary><span style="border-bottom:0.05em solid"><strong>Memory Corruption이란?</strong></span></summary>
<hr>
   <p>버그로 인한 메모리 오염, 예상되지 않은 메모리 값 변경 등에 의해 일어남</p>
- Program이 개발자가 의도하지 않은 방식으로 동작하여, 접근해서는 안되는 메모리 영역에 Write기능을 수행하여 Memory 내용이 corruption(변형)되는 것을 의미 합니다. 대부분 Programming error로 인해 Memory Corruption이 발생합니다.

- Memory Corruption의 대표적인 유형으로, Buffer Overflow가 있습니다. 즉 할당된 Buffer 크기를 너머서는 Write 작업이 이루어지면 발생됩니다. Buffer Overflow는 Stack Buffer Overflow 와 Heap Buffer Overflow 두 가지 유형으로 구분합니다

   
<hr>
</details>

<details>
   <summary><span style="border-bottom:0.05em solid"><strong>DMA란?</strong></span></summary>
<hr>
   <p>CPU를 대신하여 I/O장치와 Memory사이의 데이터전송을 담당하는 장치</p>
   <p>주변장치(하드디스크, 그래픽카드)들이 메모리에 직접 접근하여 읽거나 쓰도록 하는 기능</p>
   <p>CPU의 개입 없이 I/O장치와 기억장치 사이의 데이터를 전송할수있음</p>
   <p>인터럽트 발생 횟수 최소화하여 성능 높임</p>

<hr>
</details>

<details>
   <summary><span style="border-bottom:0.05em solid"><strong>Trashing</strong></span></summary>
<hr>
   
- 메모리 영역에 접근하게 될 때, 메모리에 페이지 부재(=페이지 폴트(Page fault)율이 높은 것을 의미한다.
   
   
- Page Fault, Page Replacement가 발생하면서 다양한 프로세스가 메모리에 올라오면 메모리의 유효공간은 줄어들고 CPU의 가동시간이 올라가면서 자원을 최대한 활용하는 상태에 이른다.
   
   
- 시간이 흐르면 CPU 사용률이 떨어지게 되는데 이는 메모리에 프로세스가 많아지면서 프로세스당 물리 메모리를 사용할 수 있는 프레임의 개수가 줄어들고, 페이지가 물리 메모리에 적게 올라온 프로세스는 명령을 조금만 수행해도 Page Fault가 발생하여 Page Replacement를 진행 하게 되기 때문이다.
   
   
- Page Replacement로 Swap 공간에서 페이지를 가져오기까지 상대적으로 오랜 시간이 걸리기 때문에 그동안 다른 프로세스가 CPU를 넘겨받지만 그 프로세스도 곧 Page Replacement를 진행하게 된다.
- 결과적으로 모든 프로세스들이 페이지를 교체하느라 바쁘고 CPU는 할일이 없어서 쉬게 되는데 CPU가 놀고있는 것을 발견한 운영체제는 더 많은 프로세스를 메모리에 올리면서 악순환이 반복된다.
- 이 현상을 Trashing이라고 한다.
- Trashing을 해소하기 위해 운영체제는 Working Set 알고리즘과 Page Fault Frequency 알고리즘 을 사용한다.
- Working Set 알고리즘은 대부분의 프로세스가 일정한 페이지만 집중적으로 참조한다는 성격을 이용해서 특정 시간동안 참조되는 페이지 개수를 파악하여 그 페이지 개수만큼 프레임이 확보되면 그때 페이지들을 메모리에 올리는 알고리즘이다.
- Page Replacement 활동을 진행할 때도 프로세스마다 Working Set 단위로 페이지를 쫓아낸다.
- Page Fault Frequency 알고리즘은 Page Fault 퍼센트의 상한과 하한을 두고 상한을 넘으면 지급하는 프레임 개수를 늘리고, 하한을 넘으면 지급 프레임 개수를 줄인다.
- 이도 남는 프레임이 없으면 프로세스 단위로 페이지를 쫓아낸다
   
<hr>
</details>

